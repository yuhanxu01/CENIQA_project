# Google Colab å¯è§†åŒ–å®Œæ•´æŒ‡å—

## é—®é¢˜ï¼šå¯è§†åŒ–å‘½ä»¤å¤±è´¥

å¦‚æœä½ çœ‹åˆ°è¿™äº›é”™è¯¯ï¼š
- `ModuleNotFoundError: No module named 'torch'`
- `experiments/resnet18_large_10k/: No such file or directory`

**åŸå› **ï¼šä½ åœ¨ä¸€ä¸ªç¯å¢ƒä¸­è®­ç»ƒï¼Œè¯•å›¾åœ¨å¦ä¸€ä¸ªç¯å¢ƒä¸­å¯è§†åŒ–

## âœ… è§£å†³æ–¹æ¡ˆï¼šåœ¨åŒä¸€ä¸ªç¯å¢ƒä¸­è¿è¡Œ

### å®Œæ•´çš„ Colab Workflow

```python
# ============================================
# å®Œæ•´çš„è®­ç»ƒå’Œå¯è§†åŒ–æµç¨‹ï¼ˆåœ¨Google Colabä¸­ï¼‰
# ============================================

# 1. å…‹éš†ä»“åº“ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
!git clone https://github.com/yuhanxu01/CENIQA_project.git
%cd CENIQA_project

# 2. åˆ‡æ¢åˆ°æ­£ç¡®çš„åˆ†æ”¯
!git checkout claude/resnet18-distorted-images-training-011CUrFBWVpjMy2D1UaHbtMx

# 3. å®‰è£…ä¾èµ–ï¼ˆColabé€šå¸¸å·²ç»æœ‰äº†ï¼‰
!pip install datasets scikit-learn

# 4. æ£€æŸ¥GPU
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}")

# 5. è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚æœè¿˜æ²¡è®­ç»ƒï¼‰
!python train_with_distortions.py \
  --experiment_name resnet18_large_10k \
  --backbone resnet18 \
  --train_samples 1666 \
  --val_samples 166 \
  --epochs 50 \
  --batch_size 64

# 6. æ£€æŸ¥è®­ç»ƒç»“æœ
!ls -lh experiments/resnet18_large_10k/

# 7. è¿è¡Œå¯è§†åŒ–
!python enhanced_visualize.py \
  --experiment experiments/resnet18_large_10k \
  --checkpoint best_model.pth \
  --num_images 25 \
  --test_samples 500

# 8. æ˜¾ç¤ºç”Ÿæˆçš„å›¾åƒ
from IPython.display import Image, display
import os

viz_dir = 'experiments/resnet18_large_10k'
images = [
    'enhanced_visualization.png',
    'cluster_analysis.png',
    'prediction_scatter.png'
]

for img in images:
    img_path = os.path.join(viz_dir, img)
    if os.path.exists(img_path):
        print(f"\n{'='*50}")
        print(f"ğŸ“Š {img}")
        print('='*50)
        display(Image(img_path))
    else:
        print(f"âš ï¸  {img} not found")

# 9. æŸ¥çœ‹è®­ç»ƒå†å²
import json
with open('experiments/resnet18_large_10k/training_history.json', 'r') as f:
    history = json.load(f)

# æ˜¾ç¤ºæœ€ä½³ç»“æœ
import pandas as pd
df = pd.DataFrame(history)
print("\n" + "="*50)
print("ğŸ“ˆ Training Summary")
print("="*50)
print(f"Best SRCC: {df['srcc'].max():.4f} (Epoch {df['srcc'].idxmax() + 1})")
print(f"Best PLCC: {df['plcc'].max():.4f} (Epoch {df['plcc'].idxmax() + 1})")
print(f"Final SRCC: {df['srcc'].iloc[-1]:.4f}")
print(f"Final PLCC: {df['plcc'].iloc[-1]:.4f}")

# ç»˜åˆ¶è®­ç»ƒæ›²çº¿
import matplotlib.pyplot as plt

fig, axes = plt.subplots(2, 2, figsize=(12, 10))

# SRCC
axes[0, 0].plot(df['epoch'], df['srcc'], marker='o', linewidth=2)
axes[0, 0].set_xlabel('Epoch')
axes[0, 0].set_ylabel('SRCC')
axes[0, 0].set_title('Spearman Correlation')
axes[0, 0].grid(True, alpha=0.3)

# PLCC
axes[0, 1].plot(df['epoch'], df['plcc'], marker='o', linewidth=2, color='orange')
axes[0, 1].set_xlabel('Epoch')
axes[0, 1].set_ylabel('PLCC')
axes[0, 1].set_title('Pearson Correlation')
axes[0, 1].grid(True, alpha=0.3)

# Loss
axes[1, 0].plot(df['epoch'], df['train_loss'], label='Train', marker='o', linewidth=2)
axes[1, 0].plot(df['epoch'], df['val_loss'], label='Val', marker='s', linewidth=2)
axes[1, 0].set_xlabel('Epoch')
axes[1, 0].set_ylabel('Loss')
axes[1, 0].set_title('Training & Validation Loss')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# Learning Rate
axes[1, 1].plot(df['epoch'], df['lr'], marker='o', linewidth=2, color='green')
axes[1, 1].set_xlabel('Epoch')
axes[1, 1].set_ylabel('Learning Rate')
axes[1, 1].set_title('Learning Rate Schedule')
axes[1, 1].set_yscale('log')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('experiments/resnet18_large_10k/training_curves.png', dpi=150, bbox_inches='tight')
plt.show()

print("\nâœ… All visualizations complete!")
```

## ğŸ¯ å¿«é€Ÿè°ƒè¯•

### æ£€æŸ¥å½“å‰çŠ¶æ€

```python
# æ£€æŸ¥æ˜¯å¦åœ¨æ­£ç¡®çš„ç›®å½•
!pwd

# æ£€æŸ¥å®éªŒç›®å½•
!ls -la experiments/ 2>/dev/null || echo "No experiments directory"

# æ£€æŸ¥ç‰¹å®šå®éªŒ
!ls -la experiments/resnet18_large_10k/ 2>/dev/null || echo "Experiment not found - need to train first"

# æ£€æŸ¥PythonåŒ…
import sys
print(f"Python: {sys.version}")

try:
    import torch
    print(f"âœ… PyTorch: {torch.__version__}")
    print(f"âœ… CUDA: {torch.cuda.is_available()}")
except ImportError:
    print("âŒ PyTorch not installed")

try:
    import numpy
    print(f"âœ… NumPy: {numpy.__version__}")
except ImportError:
    print("âŒ NumPy not installed")
```

### å¦‚æœè®­ç»ƒå·²å®Œæˆä½†å¯è§†åŒ–å¤±è´¥

```python
# 1. ç¡®è®¤æ–‡ä»¶å­˜åœ¨
import os
exp_dir = 'experiments/resnet18_large_10k'

print("Checking files...")
required_files = [
    'best_model.pth',
    'config.json',
    'training_history.json'
]

for f in required_files:
    path = os.path.join(exp_dir, f)
    exists = os.path.exists(path)
    size = os.path.getsize(path) if exists else 0
    status = "âœ…" if exists else "âŒ"
    print(f"{status} {f}: {size/1024/1024:.2f} MB" if size > 0 else f"{status} {f}: missing")

# 2. æ‰‹åŠ¨è¿è¡Œå¯è§†åŒ–
!python enhanced_visualize.py \
  --experiment experiments/resnet18_large_10k \
  --checkpoint best_model.pth \
  --num_images 25 \
  --test_samples 500 \
  --device cuda

# 3. å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼ŒæŸ¥çœ‹å®Œæ•´é”™è¯¯
!python enhanced_visualize.py \
  --experiment experiments/resnet18_large_10k \
  --checkpoint best_model.pth \
  --num_images 25 \
  --test_samples 500 2>&1 | head -50
```

## ğŸ“¥ ä¸‹è½½ç»“æœåˆ°æœ¬åœ°

å¦‚æœæƒ³åœ¨æœ¬åœ°æŸ¥çœ‹ï¼š

```python
# åœ¨Colabä¸­ï¼šæ‰“åŒ…å®éªŒç»“æœ
!zip -r resnet18_large_10k_results.zip experiments/resnet18_large_10k/

# ä¸‹è½½
from google.colab import files
files.download('resnet18_large_10k_results.zip')

# åœ¨æœ¬åœ°ï¼šè§£å‹å¹¶æŸ¥çœ‹
# unzip resnet18_large_10k_results.zip
# open experiments/resnet18_large_10k/*.png
```

## ğŸ› å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ

### é”™è¯¯ 1: ModuleNotFoundError: No module named 'torch'

**åŸå› **ï¼šç¯å¢ƒä¸åŒ¹é…

**è§£å†³**ï¼šåœ¨è®­ç»ƒçš„åŒä¸€ä¸ªç¯å¢ƒä¸­è¿è¡Œå¯è§†åŒ–

### é”™è¯¯ 2: experiments/resnet18_large_10k/: No such file or directory

**åŸå› **ï¼šè¿˜æ²¡è®­ç»ƒæ¨¡å‹

**è§£å†³**ï¼š
```python
# è¿è¡Œè®­ç»ƒ
!python train_with_distortions.py \
  --experiment_name resnet18_large_10k \
  --train_samples 1666 \
  --epochs 50
```

### é”™è¯¯ 3: RuntimeError: CUDA out of memory

**åŸå› **ï¼šGPUå†…å­˜ä¸è¶³

**è§£å†³**ï¼š
```python
# å‡å°‘batch sizeå’Œæµ‹è¯•æ ·æœ¬
!python enhanced_visualize.py \
  --experiment experiments/resnet18_large_10k \
  --checkpoint best_model.pth \
  --num_images 16 \
  --test_samples 200
```

### é”™è¯¯ 4: FileNotFoundError: [Errno 2] No such file or directory: 'best_model.pth'

**åŸå› **ï¼šæ£€æŸ¥ç‚¹æ–‡ä»¶åä¸å¯¹

**è§£å†³**ï¼š
```python
# æ£€æŸ¥å¯ç”¨çš„æ£€æŸ¥ç‚¹
!ls experiments/resnet18_large_10k/*.pth

# ä½¿ç”¨æ­£ç¡®çš„æ–‡ä»¶å
# å¦‚æœæœ‰ last_model.pthï¼š
!python enhanced_visualize.py \
  --experiment experiments/resnet18_large_10k \
  --checkpoint last_model.pth \
  --num_images 25 \
  --test_samples 500
```

## ğŸ“Š å®Œæ•´ç¤ºä¾‹è¾“å‡º

æˆåŠŸè¿è¡Œåä½ ä¼šçœ‹åˆ°ï¼š

```
Loading model from: experiments/resnet18_large_10k/best_model.pth
Model configuration:
  - Backbone: resnet18
  - Feature dim: 512
  - Clusters: 8
  - Hidden dim: 512

Loading test dataset...
Processing 500 images...
Loading test: 100% 500/500 [00:00<00:00, 1882.24it/s]

Running inference...
Inference: 100% 4/4 [00:02<00:00,  1.54it/s]

Performance metrics:
  SRCC: 0.7842
  PLCC: 0.7956
  RMSE: 0.1234

Generating visualizations...
âœ… Saved: experiments/resnet18_large_10k/enhanced_visualization.png
âœ… Saved: experiments/resnet18_large_10k/cluster_analysis.png
âœ… Saved: experiments/resnet18_large_10k/prediction_scatter.png

Done!
```

## ğŸ¨ æŸ¥çœ‹å¯è§†åŒ–ç»“æœ

```python
from IPython.display import Image, display

# ä¸»å¯è§†åŒ–
display(Image('experiments/resnet18_large_10k/enhanced_visualization.png'))

# èšç±»åˆ†æ
display(Image('experiments/resnet18_large_10k/cluster_analysis.png'))

# é¢„æµ‹æ•£ç‚¹å›¾
display(Image('experiments/resnet18_large_10k/prediction_scatter.png'))
```

## ğŸ’¡ æç¤º

1. **åœ¨åŒä¸€ä¸ªç¯å¢ƒä¸­è¿è¡Œæ‰€æœ‰æ­¥éª¤**ï¼ˆè®­ç»ƒ + å¯è§†åŒ–ï¼‰
2. **ä½¿ç”¨Colabçš„æŒä¹…åŒ–å­˜å‚¨**ï¼ˆGoogle Driveï¼‰ä¿å­˜ç»“æœ
3. **å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹**ä»¥é˜²ä¼šè¯æ–­å¼€
4. **å…ˆç”¨å°æ•°æ®é›†æµ‹è¯•**ï¼ˆtrain_samples=500, epochs=10ï¼‰

## ğŸ“š ç›¸å…³æ–‡æ¡£

- `TRAINING_IMPROVEMENTS.md` - è®­ç»ƒæ”¹è¿›è¯´æ˜
- `RUN_TRAINING_AND_VIZ.md` - å®Œæ•´è®­ç»ƒæµç¨‹
- `VISUALIZATION_GUIDE_CN.md` - å¯è§†åŒ–è¯¦ç»†æŒ‡å—
