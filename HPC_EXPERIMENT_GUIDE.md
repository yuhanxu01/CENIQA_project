# HPCå®éªŒæŒ‡å—ï¼š7ä¸ªIQAæ¨¡å‹å¯¹æ¯”

## ğŸ“‹ å®éªŒæ¦‚è¿°

æœ¬å®éªŒæ¯”è¾ƒ7ä¸ªå›¾åƒè´¨é‡è¯„ä¼°(IQA)æ¨¡å‹ï¼š

### åŸºçº¿æ¨¡å‹
1. **0_NoGMM** - æ— GMMåŸºçº¿ï¼ˆä»…backbone + regressorï¼‰
2. **1_StandardGMM** - æ ‡å‡†GMMï¼ˆå½“å‰å®ç°ï¼šsklearn GMM + concatenateï¼‰

### GMMæ”¹è¿›æ–¹æ¡ˆï¼ˆæ¥è‡ªGMM_IMPROVEMENTS.mdï¼‰
3. **2_MoE** - æ–¹æ¡ˆ1: Mixture of Expert Regressors
4. **3_Attention** - æ–¹æ¡ˆ2: Attention-Gated Feature Fusion
5. **4_LearnableGMM** - æ–¹æ¡ˆ3: Differentiable GMM with Learnable Priors
6. **5_DistortionAware** - æ–¹æ¡ˆ4: Distortion-Aware Multi-Expert Architecture
7. **6_Complete** - æ–¹æ¡ˆ5: Complete Self-Supervised GMM-IQA Pipeline

---

## ğŸš€ ä½¿ç”¨æ­¥éª¤

### æ­¥éª¤1ï¼šä¸Šä¼ ä»£ç åˆ°HPC

```bash
# æœ¬åœ°æ‰“åŒ…
tar -czf ceniqa_project.tar.gz CENIQA_project/

# ä¸Šä¼ åˆ°HPC
scp ceniqa_project.tar.gz your_username@hpc_address:/gpfs/scratch/rl5285/

# åœ¨HPCä¸Šè§£å‹
ssh your_username@hpc_address
cd /gpfs/scratch/rl5285/
tar -xzf ceniqa_project.tar.gz
```

### æ­¥éª¤2ï¼šå‡†å¤‡æ•°æ®

```bash
# åœ¨HPCä¸Š
cd /gpfs/scratch/rl5285/CENIQA_project

# åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p data/stl10

# ä¸‹è½½STL10æ•°æ®é›†ï¼ˆæˆ–ä½¿ç”¨ä½ è‡ªå·±çš„æ•°æ®ï¼‰
# æ•°æ®é›†ä¼šåœ¨ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶è‡ªåŠ¨ä¸‹è½½
```

### æ­¥éª¤3ï¼šæµ‹è¯•è¿è¡Œï¼ˆ**é‡è¦ï¼**ï¼‰

åœ¨è¿è¡Œå®Œæ•´å®éªŒä¹‹å‰ï¼Œå…ˆç”¨æµ‹è¯•æ¨¡å¼éªŒè¯ä»£ç å’Œç¯å¢ƒï¼š

```bash
# æäº¤æµ‹è¯•ä»»åŠ¡
sbatch run_test_hpc.sh

# æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€
squeue -u $USER

# æŸ¥çœ‹æµ‹è¯•æ—¥å¿—ï¼ˆç­‰ä»»åŠ¡å¼€å§‹è¿è¡Œåï¼‰
tail -f logs/test_*.out

# æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
cat logs/test_*.err
```

**æµ‹è¯•å‚æ•°ï¼š**
- è®­ç»ƒæ ·æœ¬: 100
- éªŒè¯æ ·æœ¬: 50
- Epochs: 2
- é¢„è®¡æ—¶é—´: 10-20åˆ†é’Ÿ

**å¦‚æœæµ‹è¯•å¤±è´¥ï¼Œæ£€æŸ¥ï¼š**
1. Pythonç¯å¢ƒæ˜¯å¦æ­£ç¡®
2. æ•°æ®è·¯å¾„æ˜¯å¦å­˜åœ¨
3. GPUæ˜¯å¦å¯ç”¨
4. ä¾èµ–åŒ…æ˜¯å¦å®‰è£…

### æ­¥éª¤4ï¼šè¿è¡Œå®Œæ•´å®éªŒ

æµ‹è¯•é€šè¿‡åï¼Œæäº¤å®Œæ•´å®éªŒï¼š

```bash
# æäº¤å®Œæ•´å®éªŒä»»åŠ¡
sbatch run_full_hpc.sh

# æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€
squeue -u $USER

# å®æ—¶æŸ¥çœ‹è¾“å‡º
tail -f logs/full_*.out

# æŸ¥çœ‹é”™è¯¯ï¼ˆå¦‚æœæœ‰ï¼‰
tail -f logs/full_*.err
```

**å®Œæ•´å®éªŒå‚æ•°ï¼š**
- è®­ç»ƒæ ·æœ¬: 5000
- éªŒè¯æ ·æœ¬: 1000
- Epochs: 50
- Batch size: 32
- å­¦ä¹ ç‡: 1e-4
- é¢„è®¡æ—¶é—´: 20-40å°æ—¶ï¼ˆå–å†³äºGPUæ€§èƒ½ï¼‰

---

## ğŸ“Š æŸ¥çœ‹ç»“æœ

### å®æ—¶ç›‘æ§

```bash
# æŸ¥çœ‹å½“å‰è®­ç»ƒè¿›åº¦
tail -f logs/full_*.out

# æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µï¼ˆå¦‚æœåœ¨è®¡ç®—èŠ‚ç‚¹ä¸Šï¼‰
nvidia-smi

# æŸ¥çœ‹ä½œä¸šé˜Ÿåˆ—
squeue -u $USER
```

### å®éªŒå®Œæˆå

ç»“æœä¿å­˜åœ¨ï¼š
- **JSONç»“æœ**: `results/comparison_results_full_*.json`
- **æœ€ä½³æ¨¡å‹**: `checkpoints/*_best.pth`
- **è®­ç»ƒæ—¥å¿—**: `logs/full_*.out`

æŸ¥çœ‹ç»“æœï¼š

```bash
# æŸ¥çœ‹æœ€æ–°ç»“æœæ–‡ä»¶
ls -lt results/comparison_results_*.json | head -1

# ç¾åŒ–è¾“å‡ºJSON
python -m json.tool results/comparison_results_full_*.json | less

# æå–å…³é”®ç»“æœ
python analyze_results.py results/comparison_results_full_*.json
```

---

## ğŸ“ ç›®å½•ç»“æ„

```
CENIQA_project/
â”œâ”€â”€ compare_all_methods.py          # ä¸»å®éªŒè„šæœ¬
â”œâ”€â”€ run_test_hpc.sh                 # æµ‹è¯•æäº¤è„šæœ¬
â”œâ”€â”€ run_full_hpc.sh                 # å®Œæ•´å®éªŒæäº¤è„šæœ¬
â”œâ”€â”€ analyze_results.py              # ç»“æœåˆ†æè„šæœ¬
â”œâ”€â”€ logs/                           # SLURMæ—¥å¿—
â”‚   â”œâ”€â”€ test_*.out                  # æµ‹è¯•stdout
â”‚   â”œâ”€â”€ test_*.err                  # æµ‹è¯•stderr
â”‚   â”œâ”€â”€ full_*.out                  # å®Œæ•´å®éªŒstdout
â”‚   â””â”€â”€ full_*.err                  # å®Œæ•´å®éªŒstderr
â”œâ”€â”€ checkpoints/                    # æ¨¡å‹æ£€æŸ¥ç‚¹
â”‚   â”œâ”€â”€ 0_NoGMM_best.pth
â”‚   â”œâ”€â”€ 1_StandardGMM_best.pth
â”‚   â”œâ”€â”€ 2_MoE_best.pth
â”‚   â”œâ”€â”€ 3_Attention_best.pth
â”‚   â”œâ”€â”€ 4_LearnableGMM_best.pth
â”‚   â”œâ”€â”€ 5_DistortionAware_best.pth
â”‚   â””â”€â”€ 6_Complete_best.pth
â””â”€â”€ results/                        # å®éªŒç»“æœ
    â”œâ”€â”€ comparison_results_test_*.json
    â””â”€â”€ comparison_results_full_*.json
```

---

## ğŸ”§ è‡ªå®šä¹‰é…ç½®

å¦‚æœéœ€è¦ä¿®æ”¹å®éªŒå‚æ•°ï¼Œç¼–è¾‘ `run_full_hpc.sh`:

```bash
# ä¿®æ”¹è®­ç»ƒå‚æ•°
/gpfs/scratch/rl5285/miniconda3/envs/UNSB/bin/python3.8 compare_all_methods.py \
    --epochs 100 \              # è®­ç»ƒè½®æ•°
    --batch_size 64 \           # batchå¤§å°
    --lr 5e-5 \                 # å­¦ä¹ ç‡
    --num_train 10000 \         # è®­ç»ƒæ ·æœ¬æ•°
    --num_val 2000 \            # éªŒè¯æ ·æœ¬æ•°
    --data_root data/stl10 \    # æ•°æ®è·¯å¾„
    --output_dir results        # è¾“å‡ºç›®å½•
```

æˆ–è€…ä¿®æ”¹SLURMèµ„æºï¼š

```bash
#SBATCH --mem=80G              # å¢åŠ å†…å­˜
#SBATCH --time=72:00:00        # å»¶é•¿æ—¶é—´é™åˆ¶
#SBATCH --gres=gpu:2           # ä½¿ç”¨2ä¸ªGPUï¼ˆéœ€è¦ä¿®æ”¹ä»£ç æ”¯æŒDDPï¼‰
```

---

## âš ï¸ å¸¸è§é—®é¢˜

### 1. ä»»åŠ¡è¢«æ€æ­»ï¼ˆOOMï¼‰

**ç—‡çŠ¶**: `logs/*.err` æ˜¾ç¤º "Killed" æˆ– "Out of memory"

**è§£å†³**:
```bash
# å¢åŠ å†…å­˜
#SBATCH --mem=40G  # æ”¹ä¸ºæ›´å¤§çš„å€¼

# æˆ–å‡å°batch size
--batch_size 16
```

### 2. GPUä¸å¯ç”¨

**ç—‡çŠ¶**: ä»£ç è¿è¡Œåœ¨CPUä¸Šï¼Œé€Ÿåº¦ææ…¢

**è§£å†³**:
```bash
# æ£€æŸ¥CUDA
python -c "import torch; print(torch.cuda.is_available())"

# æ£€æŸ¥GPUåˆ†é…
echo $CUDA_VISIBLE_DEVICES

# ç¡®ä¿SLURMè„šæœ¬æœ‰
#SBATCH --gres=gpu:1
```

### 3. æ•°æ®åŠ è½½æ…¢

**ç—‡çŠ¶**: è®­ç»ƒæ—¶GPUåˆ©ç”¨ç‡ä½ï¼Œå¤§éƒ¨åˆ†æ—¶é—´åœ¨ç­‰å¾…æ•°æ®

**è§£å†³**:
```bash
# å¢åŠ num_workers
--num_workers 8  # åœ¨Pythonè„šæœ¬ä¸­ä¿®æ”¹DataLoader

# æˆ–å¢åŠ cache_size
cache_size=500  # åœ¨Pythonè„šæœ¬ä¸­ä¿®æ”¹
```

### 4. ä»»åŠ¡è¶…æ—¶

**ç—‡çŠ¶**: ä»»åŠ¡åœ¨è¾¾åˆ°æ—¶é—´é™åˆ¶åè¢«å¼ºåˆ¶ç»ˆæ­¢

**è§£å†³**:
```bash
# å»¶é•¿æ—¶é—´é™åˆ¶
#SBATCH --time=96:00:00  # 4å¤©

# æˆ–å‡å°‘epochs
--epochs 30
```

---

## ğŸ“ˆ é¢„æœŸç»“æœ

æ ¹æ®GMM_IMPROVEMENTS.mdçš„ç†è®ºåˆ†æï¼Œé¢„æœŸæ€§èƒ½æ’åºï¼ˆSRCCï¼‰ï¼š

1. **6_Complete** (0.88-0.92) - å®Œæ•´Pipelineï¼Œç»“åˆæ‰€æœ‰æœ€ä½³å®è·µ
2. **5_DistortionAware** (0.86-0.90) - æ˜¾å¼å»ºæ¨¡distortion
3. **4_LearnableGMM** (0.85-0.89) - ç«¯åˆ°ç«¯å­¦ä¹ GMM
4. **2_MoE** (0.83-0.87) - Mixture of Experts
5. **3_Attention** (0.82-0.86) - Attentionæœºåˆ¶
6. **1_StandardGMM** (0.80-0.84) - å½“å‰GMMå®ç°
7. **0_NoGMM** (0.80-0.84) - æ— GMMåŸºçº¿

**å®é™…ç»“æœå¯èƒ½æœ‰æ‰€ä¸åŒï¼Œå–å†³äºï¼š**
- æ•°æ®é›†ç‰¹æ€§
- è¶…å‚æ•°è®¾ç½®
- éšæœºåˆå§‹åŒ–
- è®­ç»ƒæ—¶é•¿

---

## ğŸ“ ç»“æœåˆ†æ

å®éªŒå®Œæˆåï¼Œä½¿ç”¨åˆ†æè„šæœ¬ï¼š

```bash
# ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š
python analyze_results.py results/comparison_results_full_*.json

# è¾“å‡ºåŒ…æ‹¬ï¼š
# 1. æ€§èƒ½å¯¹æ¯”è¡¨æ ¼
# 2. è®­ç»ƒæ›²çº¿å›¾
# 3. æ¨¡å‹æ’å
# 4. ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
```

---

## ğŸ¯ ä¸‹ä¸€æ­¥

å®éªŒå®Œæˆåï¼Œå¯ä»¥ï¼š

1. **è®ºæ–‡æ’°å†™**: ä½¿ç”¨ç»“æœå’Œå¯è§†åŒ–
2. **è¿›ä¸€æ­¥åˆ†æ**: ä½¿ç”¨ä¿å­˜çš„æ¨¡å‹è¿›è¡Œæ¨ç†
3. **è¶…å‚æ•°ä¼˜åŒ–**: é’ˆå¯¹æœ€ä½³æ¨¡å‹è¿›è¡Œè°ƒä¼˜
4. **æ‰©å±•å®éªŒ**: åœ¨æ›´å¤šæ•°æ®é›†ä¸Šæµ‹è¯•

---

## ğŸ“ å¸®åŠ©

å¦‚æœ‰é—®é¢˜ï¼Œæ£€æŸ¥ï¼š
1. SLURMæ—¥å¿—: `logs/*.err` å’Œ `logs/*.out`
2. Python traceback
3. GPU/å†…å­˜ä½¿ç”¨æƒ…å†µ

ç¥å®éªŒé¡ºåˆ©ï¼ğŸš€
