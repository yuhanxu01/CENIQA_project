# HPCè®­ç»ƒæŒ‡å— - 7ä¸ªIQAæ–¹æ³•å¯¹æ¯”å®éªŒ

## ğŸ“‹ å®éªŒæ¦‚è¿°

æœ¬å®éªŒå¯¹æ¯”7ä¸ªå›¾åƒè´¨é‡è¯„ä¼°(IQA)æ–¹æ³•ï¼š

1. **No GMM (Baseline)** - ä¸ä½¿ç”¨GMMï¼Œç›´æ¥å›å½’
2. **Vanilla GMM** - æ ‡å‡†GMM + ç‰¹å¾æ‹¼æ¥
3. **MoE GMM** - Mixture of Experts
4. **Attention GMM** - Attention-Gated Feature Fusion
5. **Learnable GMM** - å¯å­¦ä¹ çš„GMMå‚æ•°
6. **Distortion-Aware** - æ˜¾å¼å»ºæ¨¡å¤±çœŸç±»å‹
7. **Complete Pipeline** - å®Œæ•´çš„Self-Supervised Pipeline

## ğŸ“‚ æ–‡ä»¶ç»“æ„

```
CENIQA_project/
â”œâ”€â”€ train_single_method.py          # å•æ–¹æ³•è®­ç»ƒè„šæœ¬
â”œâ”€â”€ submit_quick_test.sh            # å¿«é€Ÿæµ‹è¯•æäº¤è„šæœ¬ï¼ˆ2 epochsï¼‰
â”œâ”€â”€ submit_full_training.sh         # å®Œæ•´è®­ç»ƒæäº¤è„šæœ¬ï¼ˆ60 epochsï¼‰
â”œâ”€â”€ compare_results.py              # ç»“æœå¯¹æ¯”è„šæœ¬
â”œâ”€â”€ logs/                           # SLURMæ—¥å¿—ç›®å½•
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ quick_test/                # å¿«é€Ÿæµ‹è¯•ç»“æœ
â”‚   â””â”€â”€ full_training/             # å®Œæ•´è®­ç»ƒç»“æœ
â””â”€â”€ checkpoints/
    â”œâ”€â”€ quick_test/                # å¿«é€Ÿæµ‹è¯•æ¨¡å‹
    â””â”€â”€ full_training/             # å®Œæ•´è®­ç»ƒæ¨¡å‹
```

## ğŸš€ ä½¿ç”¨æ­¥éª¤

### æ­¥éª¤1: å¿«é€Ÿæµ‹è¯•ï¼ˆéªŒè¯ç¯å¢ƒå’Œä»£ç ï¼‰

é¦–å…ˆè¿è¡Œå¿«é€Ÿæµ‹è¯•ç¡®ä¿æ‰€æœ‰ä»£ç å’Œç¯å¢ƒæ­£å¸¸ï¼š

```bash
# åˆ›å»ºå¿…è¦çš„ç›®å½•
mkdir -p logs results checkpoints

# æäº¤å¿«é€Ÿæµ‹è¯•ä»»åŠ¡ï¼ˆ1ä¸ªnodeï¼Œ7ä¸ªæ–¹æ³•ä¸²è¡Œï¼Œæ¯ä¸ª2 epochsï¼‰
sbatch submit_quick_test.sh
```

**å¿«é€Ÿæµ‹è¯•é…ç½®ï¼š**
- ç”³è¯·èµ„æº: 1ä¸ªGPU node
- è¿è¡Œæ–¹å¼: 7ä¸ªæ–¹æ³•ä¸²è¡Œè¿è¡Œï¼ˆä¸€ä¸ªæ¥ä¸€ä¸ªï¼‰
- Epochs: 2
- è®­ç»ƒæ ·æœ¬: 500å¼ å‚è€ƒå›¾ Ã— 6 = 3000æ ·æœ¬
- éªŒè¯æ ·æœ¬: 200å¼ å‚è€ƒå›¾ Ã— 6 = 1200æ ·æœ¬
- é¢„è®¡æ—¶é—´: æ¯ä¸ªæ–¹æ³• ~30-45åˆ†é’Ÿï¼Œæ€»è®¡ ~3-5å°æ—¶

**ç›‘æ§ä»»åŠ¡ï¼š**
```bash
# æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€ï¼ˆåº”è¯¥åªæœ‰1ä¸ªä»»åŠ¡ï¼‰
squeue -u $USER

# æŸ¥çœ‹å®æ—¶æ—¥å¿—ï¼ˆæ‰€æœ‰7ä¸ªæ–¹æ³•åœ¨ä¸€ä¸ªæ—¥å¿—æ–‡ä»¶ä¸­ï¼‰
tail -f logs/quick_test_all_*.out

# æŸ¥çœ‹å®Œæ•´æ—¥å¿—
cat logs/quick_test_all_*.out
```

### æ­¥éª¤2: æ£€æŸ¥å¿«é€Ÿæµ‹è¯•ç»“æœ

ç­‰å¾…æ‰€æœ‰å¿«é€Ÿæµ‹è¯•å®Œæˆåï¼Œæ£€æŸ¥ç»“æœï¼š

```bash
# æŸ¥çœ‹å¿«é€Ÿæµ‹è¯•ç»“æœ
python compare_results.py \
    --results_dir results/quick_test \
    --output_dir comparison_plots/quick_test
```

è¿™ä¼šç”Ÿæˆï¼š
- `comparison_table.csv` - å¯¹æ¯”è¡¨æ ¼
- `training_comparison.png` - è®­ç»ƒæ›²çº¿å¯¹æ¯”
- `final_comparison.png` - æœ€ç»ˆç»“æœå¯¹æ¯”

**ç¡®è®¤æ£€æŸ¥ç‚¹ï¼š**
- âœ… æ‰€æœ‰7ä¸ªä»»åŠ¡éƒ½æˆåŠŸå®Œæˆ
- âœ… æ²¡æœ‰CUDAé”™è¯¯æˆ–å†…å­˜æº¢å‡º
- âœ… è®­ç»ƒæŸå¤±æ­£å¸¸ä¸‹é™
- âœ… SRCCå’ŒPLCCæŒ‡æ ‡åˆç†ï¼ˆ>0.1ï¼‰

### æ­¥éª¤3: å®Œæ•´è®­ç»ƒ

å¿«é€Ÿæµ‹è¯•é€šè¿‡åï¼Œè¿è¡Œå®Œæ•´è®­ç»ƒï¼š

```bash
# ç»™è„šæœ¬æ·»åŠ æ‰§è¡Œæƒé™
chmod +x submit_full_training.sh

# æäº¤å®Œæ•´è®­ç»ƒä»»åŠ¡ï¼ˆ7ä¸ªnodeå¹¶è¡Œï¼Œæ¯ä¸ªæ–¹æ³•60 epochsï¼‰
./submit_full_training.sh
```

**å®Œæ•´è®­ç»ƒé…ç½®ï¼š**
- ç”³è¯·èµ„æº: 7ä¸ªGPU nodes
- è¿è¡Œæ–¹å¼: 7ä¸ªæ–¹æ³•å¹¶è¡Œè¿è¡Œï¼ˆåŒæ—¶è¿è¡Œï¼‰
- Epochs: 60
- è®­ç»ƒé›†: ~11,700å¼ å‚è€ƒå›¾ Ã— 6 = ~70,200æ ·æœ¬ (90%)
- éªŒè¯é›†: ~1,300å¼ å‚è€ƒå›¾ Ã— 6 = ~7,800æ ·æœ¬ (10%)
- Batch size: 16
- Learning rate: 1e-4
- é¢„è®¡æ—¶é—´: æ¯ä¸ªæ–¹æ³• ~8-12å°æ—¶ï¼ˆå¹¶è¡Œè¿è¡Œï¼Œæ€»æ—¶é—´ä¸å˜ï¼‰

**ç›‘æ§ä»»åŠ¡ï¼š**
```bash
# æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€ï¼ˆåº”è¯¥çœ‹åˆ°7ä¸ªä»»åŠ¡ï¼‰
squeue -u $USER

# æŸ¥çœ‹ç‰¹å®šæ–¹æ³•çš„æ—¥å¿—
tail -f logs/full_no_gmm_*.out
tail -f logs/full_moe_*.out

# æŸ¥çœ‹æ‰€æœ‰æ–¹æ³•çš„è¿›åº¦
watch -n 60 'ls -lh checkpoints/full_training/*.pth'
```

### æ­¥éª¤4: å¯¹æ¯”æœ€ç»ˆç»“æœ

æ‰€æœ‰å®Œæ•´è®­ç»ƒå®Œæˆåï¼Œç”Ÿæˆå¯¹æ¯”æŠ¥å‘Šï¼š

```bash
# å¯¹æ¯”æ‰€æœ‰æ–¹æ³•çš„ç»“æœ
python compare_results.py \
    --results_dir results/full_training \
    --output_dir comparison_plots/full_training
```

è¾“å‡ºæ–‡ä»¶ï¼š
- `comparison_table.csv` - è¯¦ç»†å¯¹æ¯”è¡¨æ ¼
- `training_comparison.png` - è®­ç»ƒè¿‡ç¨‹å¯¹æ¯”ï¼ˆ4ä¸ªå­å›¾ï¼‰
- `final_comparison.png` - æœ€ç»ˆç»“æœå¯¹æ¯”ï¼ˆSRCC vs PLCCï¼‰

## ğŸ“Š æŸ¥çœ‹ç»“æœ

### å‘½ä»¤è¡ŒæŸ¥çœ‹

```bash
# æŸ¥çœ‹CSVè¡¨æ ¼
column -t -s, comparison_plots/full_training/comparison_table.csv | less -S

# æŸ¥çœ‹æœ€ä½³ç»“æœ
cat results/full_training/*_results_*.json | grep -A 3 "best_srcc"
```

### ä¸‹è½½ç»“æœåˆ°æœ¬åœ°

```bash
# åœ¨æœ¬åœ°æœºå™¨ä¸Šè¿è¡Œ
scp -r username@hpc:/path/to/CENIQA_project/comparison_plots ./
scp -r username@hpc:/path/to/CENIQA_project/results ./
```

## ğŸ”§ å•ç‹¬è®­ç»ƒæŸä¸ªæ–¹æ³•

å¦‚æœéœ€è¦å•ç‹¬è®­ç»ƒæŸä¸ªç‰¹å®šæ–¹æ³•ï¼š

```bash
# å¿«é€Ÿæµ‹è¯•æ¨¡å¼
python train_single_method.py \
    --method moe \
    --quick_test

# å®Œæ•´è®­ç»ƒæ¨¡å¼
python train_single_method.py \
    --method moe \
    --epochs 60 \
    --batch_size 16 \
    --lr 1e-4 \
    --output_dir results/full_training \
    --checkpoint_dir checkpoints/full_training
```

å¯ç”¨çš„æ–¹æ³•ï¼š
- `no_gmm` - No GMM Baseline
- `vanilla_gmm` - Vanilla GMM
- `moe` - MoE GMM
- `attention` - Attention GMM
- `learnable_gmm` - Learnable GMM
- `distortion_aware` - Distortion-Aware
- `complete` - Complete Pipeline

## ğŸ“ˆ é¢„æœŸç»“æœ

åŸºäºåˆæ­¥æµ‹è¯•ï¼Œé¢„æœŸæ’åï¼ˆä»…ä¾›å‚è€ƒï¼‰ï¼š

1. **Complete Pipeline** - ç»¼åˆæ‰€æœ‰æ”¹è¿›
2. **Learnable GMM** - è‡ªé€‚åº”GMMå‚æ•°
3. **MoE GMM** - ä¸“å®¶æ··åˆæ¨¡å‹
4. **Distortion-Aware** - æ˜¾å¼å»ºæ¨¡å¤±çœŸ
5. **Attention GMM** - æ³¨æ„åŠ›æœºåˆ¶
6. **Vanilla GMM** - æ ‡å‡†GMM
7. **No GMM** - æ— GMMåŸºçº¿

å®é™…ç»“æœå¯èƒ½å› æ•°æ®é›†å’Œè¶…å‚æ•°è®¾ç½®è€Œå¼‚ã€‚

## ğŸ› å¸¸è§é—®é¢˜

### Q1: ä»»åŠ¡ä¸€ç›´åœ¨é˜Ÿåˆ—ä¸­ç­‰å¾…
```bash
# æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€
squeue -u $USER

# æŸ¥çœ‹åˆ†åŒºå¯ç”¨æ€§
sinfo -p gpu4_medium
```

### Q2: å†…å­˜ä¸è¶³é”™è¯¯
å‡å°‘batch sizeæˆ–å¢åŠ å†…å­˜ï¼š
```bash
# ä¿®æ”¹submitè„šæœ¬ä¸­çš„ï¼š
#SBATCH --mem=40G  # å¢åŠ åˆ°40G
```

### Q3: CUDAé”™è¯¯
æ£€æŸ¥GPUå¯ç”¨æ€§ï¼š
```bash
# åœ¨è®¡ç®—èŠ‚ç‚¹ä¸Š
nvidia-smi
```

### Q4: é‡æ–°è¿è¡ŒæŸä¸ªå¤±è´¥çš„æ–¹æ³•
```bash
# å•ç‹¬æäº¤
sbatch <<EOF
#!/bin/bash
#SBATCH --job-name=retry_moe
#SBATCH --partition=gpu4_medium
#SBATCH --nodes=1
#SBATCH --cpus-per-task=7
#SBATCH --mem=20G
#SBATCH --gres=gpu:1
#SBATCH --output=logs/retry_moe_%j.out

/gpfs/scratch/rl5285/miniconda3/envs/UNSB/bin/python3.8 train_single_method.py \
    --method moe \
    --epochs 60 \
    --output_dir results/full_training \
    --checkpoint_dir checkpoints/full_training
EOF
```

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **ç¡®ä¿ç¯å¢ƒæ­£ç¡®**ï¼šPython 3.8ï¼Œå·²å®‰è£…æ‰€æœ‰ä¾èµ–
2. **æ£€æŸ¥è·¯å¾„**ï¼šä¿®æ”¹è„šæœ¬ä¸­çš„Pythonè·¯å¾„ä¸ºä½ çš„ç¯å¢ƒè·¯å¾„
3. **ç£ç›˜ç©ºé—´**ï¼šç¡®ä¿æœ‰è¶³å¤Ÿç©ºé—´å­˜å‚¨æ¨¡å‹å’Œç»“æœï¼ˆ~10GBï¼‰
4. **GPUèµ„æº**ï¼šç¡®è®¤åˆ†åŒºå’ŒGPUç±»å‹å¯ç”¨
5. **æ—¥å¿—ç›‘æ§**ï¼šå®šæœŸæ£€æŸ¥æ—¥å¿—ç¡®ä¿è®­ç»ƒæ­£å¸¸è¿›è¡Œ

## ğŸ“§ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ï¼š
1. SLURMæ—¥å¿—æ–‡ä»¶ï¼š`logs/*.err`
2. Pythonè¾“å‡ºæ—¥å¿—ï¼š`logs/*.out`
3. è®­ç»ƒç»“æœJSONï¼š`results/*/*.json`

ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸš€
