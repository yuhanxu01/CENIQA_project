# HPCå¿«é€Ÿå¼€å§‹æŒ‡å—

## âš¡ 30ç§’å¿«é€Ÿå¼€å§‹

```bash
# 1. ä¸Šä¼ ä»£ç åˆ°HPCï¼ˆåœ¨æœ¬åœ°ï¼‰
tar -czf ceniqa.tar.gz CENIQA_project/
scp ceniqa.tar.gz your_user@hpc:/gpfs/scratch/rl5285/

# 2. SSHåˆ°HPCå¹¶è§£å‹
ssh your_user@hpc
cd /gpfs/scratch/rl5285/
tar -xzf ceniqa.tar.gz
cd CENIQA_project

# 3. å…ˆæµ‹è¯•ï¼ˆ2 epochsï¼Œ100æ ·æœ¬ï¼Œ~10åˆ†é’Ÿï¼‰
sbatch run_test_hpc.sh

# 4. æŸ¥çœ‹æµ‹è¯•ç»“æœ
tail -f logs/test_*.out

# 5. æµ‹è¯•é€šè¿‡åè¿è¡Œå®Œæ•´å®éªŒï¼ˆ50 epochsï¼Œ5000æ ·æœ¬ï¼Œ~30å°æ—¶ï¼‰
sbatch run_full_hpc.sh

# 6. å®æ—¶ç›‘æ§
tail -f logs/full_*.out
```

## ğŸ“Š å®éªŒå®ŒæˆåæŸ¥çœ‹ç»“æœ

```bash
# æŸ¥çœ‹ç»“æœæ‘˜è¦
python analyze_results.py results/comparison_results_full_*.json

# ç”Ÿæˆå¯è§†åŒ–ï¼ˆåŒ…å«è®­ç»ƒæ›²çº¿ã€æ€§èƒ½æ’åã€LaTeXè¡¨æ ¼ï¼‰
python analyze_results.py results/comparison_results_full_*.json --output_dir plots
```

---

## ğŸ¯ å®éªŒå†…å®¹

### 7ä¸ªæ¨¡å‹å¯¹æ¯”ï¼š

**åŸºçº¿æ¨¡å‹ï¼š**
1. `0_NoGMM` - æ— GMMï¼ˆä»…CNN + Regressorï¼‰
2. `1_StandardGMM` - æ ‡å‡†GMMï¼ˆå½“å‰å®ç°ï¼‰

**GMMæ”¹è¿›æ–¹æ¡ˆï¼š**
3. `2_MoE` - Mixture of Experts
4. `3_Attention` - Attention-Gated Fusion
5. `4_LearnableGMM` - Learnable GMM
6. `5_DistortionAware` - Distortion-Aware Multi-Expert
7. `6_Complete` - Complete Self-Supervised Pipeline

### è¯„ä¼°æŒ‡æ ‡ï¼š
- **SRCC** (Spearman Rank Correlation Coefficient)
- **PLCC** (Pearson Linear Correlation Coefficient)

---

## ğŸ“ é‡è¦æ–‡ä»¶

| æ–‡ä»¶ | è¯´æ˜ |
|------|------|
| `compare_all_methods.py` | ä¸»å®éªŒè„šæœ¬ï¼ˆ7ä¸ªæ¨¡å‹ï¼‰ |
| `run_test_hpc.sh` | æµ‹è¯•æäº¤è„šæœ¬ï¼ˆ2 epochsï¼‰ |
| `run_full_hpc.sh` | å®Œæ•´å®éªŒæäº¤è„šæœ¬ï¼ˆ50 epochsï¼‰ |
| `analyze_results.py` | ç»“æœåˆ†æå’Œå¯è§†åŒ– |
| `HPC_EXPERIMENT_GUIDE.md` | è¯¦ç»†å®éªŒæŒ‡å— |

---

## âš™ï¸ è‡ªå®šä¹‰å‚æ•°

### ä¿®æ”¹è®­ç»ƒå‚æ•°

ç¼–è¾‘ `run_full_hpc.sh`ï¼Œä¿®æ”¹è¿™äº›å‚æ•°ï¼š

```bash
python compare_all_methods.py \
    --epochs 100 \              # è®­ç»ƒè½®æ•°
    --batch_size 64 \           # batchå¤§å°
    --lr 5e-5 \                 # å­¦ä¹ ç‡
    --num_train 10000 \         # è®­ç»ƒæ ·æœ¬æ•°
    --num_val 2000              # éªŒè¯æ ·æœ¬æ•°
```

### ä¿®æ”¹SLURMèµ„æº

ç¼–è¾‘ `run_full_hpc.sh` å¼€å¤´çš„SBATCHå‚æ•°ï¼š

```bash
#SBATCH --mem=40G              # å†…å­˜
#SBATCH --time=48:00:00        # æ—¶é—´é™åˆ¶
#SBATCH --cpus-per-task=7      # CPUæ ¸å¿ƒæ•°
#SBATCH --gres=gpu:1           # GPUæ•°é‡
```

---

## ğŸ” ç›‘æ§å’Œè°ƒè¯•

### æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€
```bash
squeue -u $USER                # æŸ¥çœ‹é˜Ÿåˆ—
scontrol show job <job_id>     # æŸ¥çœ‹ä»»åŠ¡è¯¦æƒ…
scancel <job_id>               # å–æ¶ˆä»»åŠ¡
```

### æŸ¥çœ‹æ—¥å¿—
```bash
# å®æ—¶æŸ¥çœ‹è¾“å‡º
tail -f logs/full_*.out

# æŸ¥çœ‹é”™è¯¯
cat logs/full_*.err

# æŸ¥çœ‹GPUä½¿ç”¨ï¼ˆåœ¨è®¡ç®—èŠ‚ç‚¹ä¸Šï¼‰
nvidia-smi
```

### å¸¸è§é”™è¯¯

**Out of Memory (OOM)**
```bash
# è§£å†³ï¼šå‡å°batch sizeæˆ–å¢åŠ å†…å­˜
--batch_size 16
#SBATCH --mem=80G
```

**ä»»åŠ¡è¶…æ—¶**
```bash
# è§£å†³ï¼šå»¶é•¿æ—¶é—´é™åˆ¶æˆ–å‡å°‘epochs
#SBATCH --time=72:00:00
--epochs 30
```

---

## ğŸ“ˆ é¢„æœŸç»“æœ

åŸºäºç†è®ºåˆ†æçš„é¢„æœŸæ€§èƒ½æ’åºï¼ˆSRCCï¼‰ï¼š

1. ğŸ¥‡ **6_Complete** (0.88-0.92)
2. ğŸ¥ˆ **5_DistortionAware** (0.86-0.90)
3. ğŸ¥‰ **4_LearnableGMM** (0.85-0.89)
4. **2_MoE** (0.83-0.87)
5. **3_Attention** (0.82-0.86)
6. **1_StandardGMM** (0.80-0.84)
7. **0_NoGMM** (0.80-0.84)

*å®é™…ç»“æœå¯èƒ½å› æ•°æ®é›†å’Œè¶…å‚æ•°è€Œå¼‚*

---

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

è¯¦ç»†æŒ‡å—è¯·æŸ¥çœ‹ï¼š
- `HPC_EXPERIMENT_GUIDE.md` - å®Œæ•´å®éªŒæŒ‡å—
- `GMM_IMPROVEMENTS.md` - æ–¹æ³•ç†è®ºè¯´æ˜
- `logs/*.err` - é”™è¯¯æ—¥å¿—

ç¥å®éªŒé¡ºåˆ©ï¼ğŸš€
