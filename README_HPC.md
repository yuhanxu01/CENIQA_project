# HPCå¹¶è¡Œè®­ç»ƒï¼š7ä¸ªIQAæ–¹æ³•å¯¹æ¯”å®éªŒ

## ğŸ“ é¡¹ç›®æ–‡ä»¶è¯´æ˜

### ä¸»è¦è„šæœ¬
- **`train_single_method.py`** - æ ¸å¿ƒè®­ç»ƒè„šæœ¬ï¼Œæ”¯æŒ7ä¸ªæ–¹æ³•çš„ç‹¬ç«‹è®­ç»ƒ
- **`submit_quick_test.sh`** - æäº¤å¿«é€Ÿæµ‹è¯•ï¼ˆ2 epochsï¼ŒéªŒè¯ç¯å¢ƒï¼‰
- **`submit_full_training.sh`** - æäº¤å®Œæ•´è®­ç»ƒï¼ˆ60 epochsï¼‰
- **`compare_results.py`** - ç»“æœå¯¹æ¯”å’Œå¯è§†åŒ–
- **`test_local.sh`** - æœ¬åœ°æµ‹è¯•è„šæœ¬ï¼ˆæäº¤HPCå‰éªŒè¯ï¼‰

### æ–‡æ¡£
- **`QUICK_START.md`** - â­ å¿«é€Ÿå¼€å§‹æŒ‡å—ï¼ˆä»è¿™é‡Œå¼€å§‹ï¼‰
- **`HPC_TRAINING_GUIDE.md`** - è¯¦ç»†ä½¿ç”¨æ–‡æ¡£
- **`README_HPC.md`** - æœ¬æ–‡ä»¶

## ğŸ¯ 7ä¸ªå®éªŒæ–¹æ³•

| # | æ–¹æ³•å | å‘½ä»¤è¡Œå‚æ•° | è¯´æ˜ |
|---|--------|-----------|------|
| 1 | No GMM Baseline | `--method no_gmm` | ä¸ä½¿ç”¨GMMï¼Œç›´æ¥å›å½’ï¼ˆåŸºçº¿ï¼‰ |
| 2 | Vanilla GMM | `--method vanilla_gmm` | æ ‡å‡†GMM + ç‰¹å¾æ‹¼æ¥ |
| 3 | MoE GMM | `--method moe` | Mixture of Expertsï¼ˆæ¯ä¸ªclusterä¸€ä¸ªexpertï¼‰ |
| 4 | Attention GMM | `--method attention` | Attentionæœºåˆ¶èåˆclusterç‰¹å¾ |
| 5 | Learnable GMM | `--method learnable_gmm` | å¯å­¦ä¹ çš„GMMå‚æ•° |
| 6 | Distortion-Aware | `--method distortion_aware` | æ˜¾å¼å»ºæ¨¡å¤±çœŸç±»å‹ |
| 7 | Complete Pipeline | `--method complete` | ç»¼åˆæ‰€æœ‰æ”¹è¿›æŠ€æœ¯ |

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆ3æ­¥èµ°ï¼‰

### 1ï¸âƒ£ æœ¬åœ°éªŒè¯ï¼ˆå¯é€‰ä½†æ¨èï¼‰

åœ¨æœ¬åœ°æœºå™¨ä¸Šå¿«é€ŸéªŒè¯ä»£ç ï¼š

```bash
./test_local.sh
```

è¿™ä¼šç”¨æå°‘é‡æ•°æ®æµ‹è¯•æ‰€æœ‰7ä¸ªæ–¹æ³•ï¼ˆ10-20åˆ†é’Ÿï¼‰

### 2ï¸âƒ£ HPCå¿«é€Ÿæµ‹è¯•ï¼ˆå¿…é¡»ï¼‰

ä¸Šä¼ ä»£ç åˆ°HPCåï¼Œå…ˆè¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼š

```bash
# åœ¨HPCä¸Š
cd /gpfs/scratch/rl5285/CENIQA_project
./submit_quick_test.sh

# ç›‘æ§ä»»åŠ¡
squeue -u $USER
tail -f logs/quick_*.out
```

ç­‰å¾…å®Œæˆåæ£€æŸ¥ç»“æœï¼š

```bash
python compare_results.py \
    --results_dir results/quick_test \
    --output_dir comparison_plots/quick_test
```

### 3ï¸âƒ£ å®Œæ•´è®­ç»ƒ

å¿«é€Ÿæµ‹è¯•é€šè¿‡åï¼Œè¿è¡Œå®Œæ•´è®­ç»ƒï¼š

```bash
./submit_full_training.sh

# ç­‰å¾…å®Œæˆå
python compare_results.py \
    --results_dir results/full_training \
    --output_dir comparison_plots/full_training
```

## ğŸ“Š å®éªŒé…ç½®

### å¿«é€Ÿæµ‹è¯•
- **ç›®çš„**: éªŒè¯ä»£ç å’Œç¯å¢ƒ
- **Epochs**: 2
- **æ•°æ®**: 500è®­ç»ƒæ ·æœ¬ + 200éªŒè¯æ ·æœ¬
- **æ—¶é—´**: æ¯ä¸ªæ–¹æ³•30-45åˆ†é’Ÿï¼Œæ€»è®¡3-5å°æ—¶

### å®Œæ•´è®­ç»ƒ
- **ç›®çš„**: è·å¾—æœ€ç»ˆå¯¹æ¯”ç»“æœ
- **Epochs**: 60
- **æ•°æ®**: 70,200è®­ç»ƒæ ·æœ¬ + 7,800éªŒè¯æ ·æœ¬ï¼ˆ90/10åˆ†å‰²ï¼‰
- **æ—¶é—´**: æ¯ä¸ªæ–¹æ³•8-12å°æ—¶ï¼ˆå¹¶è¡Œè¿è¡Œï¼‰

## ğŸ“ˆ é¢„æœŸç»“æœ

æ ¹æ®åˆæ­¥å®éªŒï¼Œé¢„æœŸæ€§èƒ½æ’åï¼ˆSRCCï¼‰ï¼š

1. **Complete Pipeline** (0.75-0.85) - ç»¼åˆæ‰€æœ‰æ”¹è¿›
2. **Learnable GMM** (0.70-0.80) - è‡ªé€‚åº”å‚æ•°
3. **MoE GMM** (0.65-0.75) - ä¸“å®¶æ··åˆ
4. **Distortion-Aware** (0.65-0.75) - å¤±çœŸå»ºæ¨¡
5. **Attention GMM** (0.60-0.70) - æ³¨æ„åŠ›æœºåˆ¶
6. **Vanilla GMM** (0.55-0.65) - æ ‡å‡†GMM
7. **No GMM** (0.50-0.60) - åŸºçº¿æ–¹æ³•

> å®é™…ç»“æœå¯èƒ½å› æ•°æ®é›†å’Œè¶…å‚æ•°è€Œå¼‚

## ğŸ“‚ è¾“å‡ºæ–‡ä»¶

### è®­ç»ƒç»“æœ
```
results/
â”œâ”€â”€ quick_test/
â”‚   â”œâ”€â”€ no_gmm_results_*.json
â”‚   â”œâ”€â”€ vanilla_gmm_results_*.json
â”‚   â””â”€â”€ ...
â””â”€â”€ full_training/
    â”œâ”€â”€ no_gmm_results_*.json
    â”œâ”€â”€ vanilla_gmm_results_*.json
    â””â”€â”€ ...
```

### æ¨¡å‹æƒé‡
```
checkpoints/
â”œâ”€â”€ quick_test/
â”‚   â”œâ”€â”€ no_gmm_best.pth
â”‚   â””â”€â”€ ...
â””â”€â”€ full_training/
    â”œâ”€â”€ no_gmm_best.pth
    â””â”€â”€ ...
```

### å¯¹æ¯”ç»“æœ
```
comparison_plots/
â”œâ”€â”€ quick_test/
â”‚   â”œâ”€â”€ comparison_table.csv
â”‚   â”œâ”€â”€ training_comparison.png
â”‚   â””â”€â”€ final_comparison.png
â””â”€â”€ full_training/
    â”œâ”€â”€ comparison_table.csv
    â”œâ”€â”€ training_comparison.png
    â””â”€â”€ final_comparison.png
```

## ğŸ”§ é«˜çº§ç”¨æ³•

### å•ç‹¬è®­ç»ƒæŸä¸ªæ–¹æ³•

```bash
# åœ¨HPCä¸Šæäº¤å•ä¸ªä»»åŠ¡
sbatch <<EOF
#!/bin/bash
#SBATCH --job-name=test_moe
#SBATCH --partition=gpu4_medium
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=7
#SBATCH --mem=20G

python train_single_method.py \
    --method moe \
    --epochs 60 \
    --batch_size 16 \
    --output_dir results/full_training \
    --checkpoint_dir checkpoints/full_training
EOF
```

### è‡ªå®šä¹‰å‚æ•°

```bash
python train_single_method.py \
    --method complete \
    --epochs 100 \
    --batch_size 32 \
    --lr 5e-5 \
    --max_train_samples 5000 \
    --output_dir results/custom \
    --checkpoint_dir checkpoints/custom
```

### æ¢å¤è®­ç»ƒ

ç›®å‰ä¸æ”¯æŒæ¢å¤è®­ç»ƒã€‚å¦‚æœä»»åŠ¡ä¸­æ–­ï¼Œéœ€è¦é‡æ–°å¼€å§‹ã€‚

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜1: ä»»åŠ¡æäº¤å¤±è´¥
```bash
# æ£€æŸ¥SLURMé…ç½®
sbatch --test-only submit_quick_test.sh

# æŸ¥çœ‹åˆ†åŒºçŠ¶æ€
sinfo -p gpu4_medium
```

### é—®é¢˜2: CUDAå†…å­˜ä¸è¶³
é™ä½batch sizeï¼š
```bash
python train_single_method.py --method METHOD --batch_size 8 ...
```

### é—®é¢˜3: æ•°æ®åŠ è½½æ…¢
å¢åŠ workersï¼š
```bash
# ä¿®æ”¹train_single_method.pyä¸­çš„num_workers
DataLoader(..., num_workers=8, ...)
```

### é—®é¢˜4: æŸ¥çœ‹è¯¦ç»†é”™è¯¯
```bash
# æŸ¥çœ‹SLURMé”™è¯¯æ—¥å¿—
cat logs/full_METHOD_JOBID.err

# æŸ¥çœ‹Python traceback
grep -A 20 "Traceback" logs/full_METHOD_JOBID.out
```

## ğŸ“ æ”¯æŒ

é‡åˆ°é—®é¢˜ï¼Ÿæ£€æŸ¥ï¼š

1. **æ—¥å¿—æ–‡ä»¶**: `logs/*.out` å’Œ `logs/*.err`
2. **ç»“æœæ–‡ä»¶**: `results/*/*.json`
3. **è®­ç»ƒæŒ‡å—**: `HPC_TRAINING_GUIDE.md`
4. **å¿«é€Ÿå¼€å§‹**: `QUICK_START.md`

## ğŸ”¬ å®éªŒè®¾è®¡è¯´æ˜

### å…¬å¹³å¯¹æ¯”ä¿è¯

æ‰€æœ‰7ä¸ªæ–¹æ³•ä½¿ç”¨ï¼š
- âœ… ç›¸åŒçš„æ•°æ®é›†ï¼ˆSTL-10ï¼Œ90/10åˆ†å‰²ï¼‰
- âœ… ç›¸åŒçš„backboneï¼ˆResNet-50ï¼‰
- âœ… ç›¸åŒçš„è®­ç»ƒå‚æ•°ï¼ˆlr=1e-4, batch_size=16ï¼‰
- âœ… ç›¸åŒçš„è®­ç»ƒepochsï¼ˆ60ï¼‰
- âœ… ç›¸åŒçš„è¯„ä¼°æŒ‡æ ‡ï¼ˆSRCC, PLCCï¼‰

### æ•°æ®é›†é…ç½®

- **æ•°æ®æº**: STL-10 (13,000å¼ å‚è€ƒå›¾)
- **å¤±çœŸç±»å‹**: 8ç§ï¼ˆblur, noise, jpeg, saturation, contrast, brightness, pixelationï¼‰
- **æ¯å¼ å›¾ç”Ÿæˆ**: 5ç§å¤±çœŸ + 1å¼ åŸå›¾ = 6ä¸ªæ ·æœ¬
- **æ€»æ ·æœ¬æ•°**: 78,000
- **åˆ†å‰²**: 90% è®­ç»ƒ (70,200) / 10% éªŒè¯ (7,800)
- **éšæœºç§å­**: 42ï¼ˆä¿è¯å¯å¤ç°ï¼‰

### è¯„ä¼°æŒ‡æ ‡

- **SRCC** (Spearman Rank Correlation): è¡¡é‡æ’åºä¸€è‡´æ€§
- **PLCC** (Pearson Linear Correlation): è¡¡é‡çº¿æ€§ç›¸å…³æ€§
- **ä¸»è¦æŒ‡æ ‡**: SRCCï¼ˆæ›´é²æ£’ï¼‰

## ğŸ“ å¼•ç”¨

å¦‚æœä½¿ç”¨æœ¬ä»£ç ï¼Œè¯·å¼•ç”¨åŸå§‹CENIQAè®ºæ–‡åŠç›¸å…³å·¥ä½œã€‚

---

**æœ€åæ›´æ–°**: 2025-11-17
**ä½œè€…**: Claude & Research Team
