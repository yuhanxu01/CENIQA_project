# HPCå®éªŒï¼š7ä¸ªIQAæ¨¡å‹å¯¹æ¯”

æœ¬ç›®å½•åŒ…å«å®Œæ•´çš„HPCå®éªŒä»£ç ï¼Œç”¨äºå…¬å¹³å¯¹æ¯”7ä¸ªå›¾åƒè´¨é‡è¯„ä¼°(IQA)æ¨¡å‹ã€‚

---

## ğŸ“š æ–‡ä»¶æ¸…å•

### æ ¸å¿ƒå®éªŒæ–‡ä»¶
- **`compare_all_methods.py`** - ä¸»å®éªŒè„šæœ¬ï¼Œå®ç°7ä¸ªæ¨¡å‹çš„è®­ç»ƒå’Œè¯„ä¼°
- **`compare_gmm_methods.py`** - æ—§ç‰ˆæœ¬ï¼ˆä»…5ä¸ªGMMæ–¹æ³•ï¼‰

### HPCæäº¤è„šæœ¬
- **`run_test_hpc.sh`** - æµ‹è¯•æ¨¡å¼SLURMè„šæœ¬ï¼ˆ100æ ·æœ¬ + 2 epochsï¼Œ~10åˆ†é’Ÿï¼‰
- **`run_full_hpc.sh`** - å®Œæ•´å®éªŒSLURMè„šæœ¬ï¼ˆ5000æ ·æœ¬ + 50 epochsï¼Œ~30å°æ—¶ï¼‰
- **`run_local_test.sh`** - æœ¬åœ°æµ‹è¯•è„šæœ¬ï¼ˆå¯åœ¨æœ¬åœ°æœºå™¨ä¸ŠéªŒè¯ï¼‰

### åˆ†æå’Œæ–‡æ¡£
- **`analyze_results.py`** - ç»“æœåˆ†æå’Œå¯è§†åŒ–è„šæœ¬
- **`HPC_EXPERIMENT_GUIDE.md`** - è¯¦ç»†å®éªŒæŒ‡å—ï¼ˆæ¨èé˜…è¯»ï¼‰
- **`QUICKSTART_HPC.md`** - å¿«é€Ÿå¼€å§‹æŒ‡å—
- **`GMM_IMPROVEMENTS.md`** - GMMæ”¹è¿›æ–¹æ¡ˆç†è®ºè¯´æ˜

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³•1ï¼šHPCä¸Šè¿è¡Œï¼ˆæ¨èï¼‰

```bash
# 1. ä¸Šä¼ ä»£ç åˆ°HPC
scp -r CENIQA_project/ your_user@hpc:/gpfs/scratch/rl5285/

# 2. SSHåˆ°HPC
ssh your_user@hpc
cd /gpfs/scratch/rl5285/CENIQA_project

# 3. å…ˆæµ‹è¯•ï¼ˆé‡è¦ï¼ï¼‰
sbatch run_test_hpc.sh

# 4. æŸ¥çœ‹æµ‹è¯•æ—¥å¿—
tail -f logs/test_*.out

# 5. æµ‹è¯•é€šè¿‡åè¿è¡Œå®Œæ•´å®éªŒ
sbatch run_full_hpc.sh

# 6. ç›‘æ§è¿›åº¦
tail -f logs/full_*.out
```

### æ–¹æ³•2ï¼šæœ¬åœ°æµ‹è¯•

```bash
# åœ¨æœ¬åœ°æœºå™¨ä¸Šå¿«é€Ÿæµ‹è¯•
./run_local_test.sh

# æŸ¥çœ‹ç»“æœ
python analyze_results.py results/comparison_results_test_*.json
```

---

## ğŸ¯ å®éªŒå†…å®¹

### 7ä¸ªæ¨¡å‹

**Baselineæ¨¡å‹ï¼š**
1. **0_NoGMM** - æ— GMMåŸºçº¿ï¼ˆä»…CNN + Regressorï¼‰
2. **1_StandardGMM** - æ ‡å‡†GMMï¼ˆå½“å‰å®ç°ï¼šsklearn GMM + concatenateï¼‰

**GMMæ”¹è¿›æ–¹æ¡ˆï¼ˆæ¥è‡ªGMM_IMPROVEMENTS.mdï¼‰ï¼š**
3. **2_MoE** - æ–¹æ¡ˆ1: Mixture of Expert Regressors
4. **3_Attention** - æ–¹æ¡ˆ2: Attention-Gated Feature Fusion
5. **4_LearnableGMM** - æ–¹æ¡ˆ3: Differentiable GMM with Learnable Priors
6. **5_DistortionAware** - æ–¹æ¡ˆ4: Distortion-Aware Multi-Expert Architecture
7. **6_Complete** - æ–¹æ¡ˆ5: Complete Self-Supervised GMM-IQA Pipeline

### è¯„ä¼°æŒ‡æ ‡
- **SRCC** (Spearman Rank Correlation Coefficient) - ä¸»è¦æŒ‡æ ‡
- **PLCC** (Pearson Linear Correlation Coefficient) - æ¬¡è¦æŒ‡æ ‡

---

## ğŸ“Š å®éªŒæ¨¡å¼

### æµ‹è¯•æ¨¡å¼ï¼ˆ`--test_mode`ï¼‰
- **ç›®çš„**: å¿«é€ŸéªŒè¯ä»£ç å’Œç¯å¢ƒ
- **æ ·æœ¬æ•°**: 100è®­ç»ƒ + 50éªŒè¯
- **Epochs**: 2
- **è€—æ—¶**: ~10åˆ†é’Ÿ
- **ç”¨æ³•**: åœ¨è¿è¡Œå®Œæ•´å®éªŒä¹‹å‰å¿…é¡»å…ˆæµ‹è¯•

### å®Œæ•´æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
- **ç›®çš„**: æ­£å¼å®éªŒå’Œè®ºæ–‡ç»“æœ
- **æ ·æœ¬æ•°**: 5000è®­ç»ƒ + 1000éªŒè¯
- **Epochs**: 50
- **è€—æ—¶**: ~30å°æ—¶ï¼ˆå–å†³äºGPUï¼‰
- **ç”¨æ³•**: æµ‹è¯•é€šè¿‡åè¿è¡Œ

---

## ğŸ“‚ ç›®å½•ç»“æ„

```
CENIQA_project/
â”œâ”€â”€ compare_all_methods.py          # ä¸»å®éªŒè„šæœ¬ï¼ˆ7ä¸ªæ¨¡å‹ï¼‰
â”œâ”€â”€ analyze_results.py              # ç»“æœåˆ†æè„šæœ¬
â”‚
â”œâ”€â”€ run_test_hpc.sh                 # HPCæµ‹è¯•è„šæœ¬
â”œâ”€â”€ run_full_hpc.sh                 # HPCå®Œæ•´å®éªŒè„šæœ¬
â”œâ”€â”€ run_local_test.sh               # æœ¬åœ°æµ‹è¯•è„šæœ¬
â”‚
â”œâ”€â”€ HPC_EXPERIMENT_GUIDE.md         # è¯¦ç»†æŒ‡å—
â”œâ”€â”€ QUICKSTART_HPC.md               # å¿«é€ŸæŒ‡å—
â”œâ”€â”€ GMM_IMPROVEMENTS.md             # ç†è®ºè¯´æ˜
â”‚
â”œâ”€â”€ logs/                           # SLURMæ—¥å¿—
â”‚   â”œâ”€â”€ test_*.out                  # æµ‹è¯•stdout
â”‚   â”œâ”€â”€ test_*.err                  # æµ‹è¯•stderr
â”‚   â”œâ”€â”€ full_*.out                  # å®Œæ•´å®éªŒstdout
â”‚   â””â”€â”€ full_*.err                  # å®Œæ•´å®éªŒstderr
â”‚
â”œâ”€â”€ checkpoints/                    # æ¨¡å‹æ£€æŸ¥ç‚¹
â”‚   â”œâ”€â”€ 0_NoGMM_best.pth
â”‚   â”œâ”€â”€ 1_StandardGMM_best.pth
â”‚   â”œâ”€â”€ 2_MoE_best.pth
â”‚   â”œâ”€â”€ 3_Attention_best.pth
â”‚   â”œâ”€â”€ 4_LearnableGMM_best.pth
â”‚   â”œâ”€â”€ 5_DistortionAware_best.pth
â”‚   â””â”€â”€ 6_Complete_best.pth
â”‚
â”œâ”€â”€ results/                        # å®éªŒç»“æœ
â”‚   â”œâ”€â”€ comparison_results_test_*.json
â”‚   â””â”€â”€ comparison_results_full_*.json
â”‚
â””â”€â”€ plots/                          # å¯è§†åŒ–å›¾è¡¨
    â”œâ”€â”€ training_curves.png
    â”œâ”€â”€ performance_ranking.png
    â””â”€â”€ results_table.tex
```

---

## ğŸ”§ è‡ªå®šä¹‰é…ç½®

### ä¿®æ”¹å®éªŒå‚æ•°

ç¼–è¾‘ `run_full_hpc.sh` æˆ–ç›´æ¥è¿è¡Œï¼š

```bash
python compare_all_methods.py \
    --epochs 100 \              # è®­ç»ƒè½®æ•°
    --batch_size 64 \           # batchå¤§å°
    --lr 5e-5 \                 # å­¦ä¹ ç‡
    --num_train 10000 \         # è®­ç»ƒæ ·æœ¬æ•°
    --num_val 2000 \            # éªŒè¯æ ·æœ¬æ•°
    --data_root data/stl10 \    # æ•°æ®è·¯å¾„
    --output_dir results        # è¾“å‡ºç›®å½•
```

### ä¿®æ”¹SLURMèµ„æº

ç¼–è¾‘ `run_full_hpc.sh` çš„SBATCHå‚æ•°ï¼š

```bash
#SBATCH --mem=80G              # å¢åŠ å†…å­˜
#SBATCH --time=72:00:00        # å»¶é•¿æ—¶é—´
#SBATCH --cpus-per-task=14     # æ›´å¤šCPU
#SBATCH --gres=gpu:2           # å¤šGPUï¼ˆéœ€ä¿®æ”¹ä»£ç ï¼‰
```

---

## ğŸ“ˆ æŸ¥çœ‹å’Œåˆ†æç»“æœ

### å‘½ä»¤è¡ŒæŸ¥çœ‹

```bash
# æŸ¥çœ‹æœ€æ–°ç»“æœ
ls -lt results/comparison_results_*.json | head -1

# ç¾åŒ–JSONè¾“å‡º
python -m json.tool results/comparison_results_full_*.json | less

# è¿è¡Œåˆ†æè„šæœ¬
python analyze_results.py results/comparison_results_full_*.json
```

### ç”Ÿæˆå¯è§†åŒ–

```bash
# ç”Ÿæˆæ‰€æœ‰å›¾è¡¨
python analyze_results.py results/comparison_results_full_*.json --output_dir plots

# è¾“å‡ºåŒ…æ‹¬ï¼š
# - plots/training_curves.png     : è®­ç»ƒæ›²çº¿
# - plots/performance_ranking.png : æ€§èƒ½æ’å
# - plots/results_table.tex       : LaTeXè¡¨æ ¼
```

### è¾“å‡ºç¤ºä¾‹

```
==================================================================================================
å®éªŒç»“æœæ‘˜è¦
==================================================================================================

é…ç½®ä¿¡æ¯:
  - è®­ç»ƒæ ·æœ¬: 5000
  - éªŒè¯æ ·æœ¬: 1000
  - Epochs: 50
  - Batch size: 32
  - å­¦ä¹ ç‡: 0.0001
  - æ€»è€—æ—¶: 1523.45 åˆ†é’Ÿ

----------------------------------------------------------------------------------------------------
æ’å   æ¨¡å‹                      æœ€ä½³SRCC      æœ€ä½³PLCC      æœ€ä½³Epoch     ç›¸å¯¹æå‡
----------------------------------------------------------------------------------------------------
ğŸ†     6_Complete                0.8934       0.9012       47           +8.42%
2      5_DistortionAware         0.8812       0.8901       45           +6.94%
3      4_LearnableGMM            0.8698       0.8756       43           +5.55%
4      2_MoE                     0.8523       0.8611       41           +3.43%
5      3_Attention               0.8445       0.8534       39           +2.48%
6      1_StandardGMM             0.8291       0.8412       38           +0.61%
7      0_NoGMM                   0.8241       0.8378       37           +0.00%
----------------------------------------------------------------------------------------------------
```

---

## âš ï¸ å¸¸è§é—®é¢˜

### 1. æµ‹è¯•å¤±è´¥

**ç—‡çŠ¶**: `run_test_hpc.sh` è¿è¡Œå¤±è´¥

**è§£å†³æ­¥éª¤**:
1. æŸ¥çœ‹é”™è¯¯æ—¥å¿—: `cat logs/test_*.err`
2. æ£€æŸ¥Pythonç¯å¢ƒ: `python --version`
3. æ£€æŸ¥ä¾èµ–: `python -c "import torch; print(torch.__version__)"`
4. æ£€æŸ¥æ•°æ®è·¯å¾„: `ls data/stl10/`

### 2. Out of Memory (OOM)

**ç—‡çŠ¶**: æ—¥å¿—æ˜¾ç¤º "CUDA out of memory" æˆ– "Killed"

**è§£å†³**:
```bash
# é€‰é¡¹1: å‡å°batch size
--batch_size 16

# é€‰é¡¹2: å¢åŠ å†…å­˜
#SBATCH --mem=80G

# é€‰é¡¹3: ä½¿ç”¨æ›´å°‘æ ·æœ¬
--num_train 3000
```

### 3. ä»»åŠ¡è¶…æ—¶

**ç—‡çŠ¶**: ä»»åŠ¡åœ¨æ—¶é—´é™åˆ¶å‰è¢«å¼ºåˆ¶ç»ˆæ­¢

**è§£å†³**:
```bash
# å»¶é•¿æ—¶é—´é™åˆ¶
#SBATCH --time=96:00:00

# æˆ–å‡å°‘epochs
--epochs 30
```

### 4. GPUä¸å¯ç”¨

**ç—‡çŠ¶**: ä»£ç è¿è¡Œåœ¨CPUä¸Šï¼Œé€Ÿåº¦ææ…¢

**è§£å†³**:
```bash
# æ£€æŸ¥CUDA
python -c "import torch; print(torch.cuda.is_available())"

# ç¡®ä¿SLURMè„šæœ¬è¯·æ±‚GPU
#SBATCH --gres=gpu:1

# æ£€æŸ¥GPUåˆ†é…
echo $CUDA_VISIBLE_DEVICES
```

---

## ğŸ“– è¿›ä¸€æ­¥é˜…è¯»

- **`HPC_EXPERIMENT_GUIDE.md`** - è¯¦ç»†çš„å®éªŒæŒ‡å—ï¼ŒåŒ…å«æ‰€æœ‰ç»†èŠ‚
- **`QUICKSTART_HPC.md`** - 30ç§’å¿«é€Ÿå¼€å§‹
- **`GMM_IMPROVEMENTS.md`** - GMMæ”¹è¿›æ–¹æ¡ˆçš„ç†è®ºåŸºç¡€å’Œå‚è€ƒæ–‡çŒ®

---

## ğŸ“§ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼š
1. æŸ¥çœ‹è¯¦ç»†æŒ‡å—: `HPC_EXPERIMENT_GUIDE.md`
2. æ£€æŸ¥æ—¥å¿—: `logs/*.err`
3. æŸ¥çœ‹å·²çŸ¥é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆï¼ˆä¸Šæ–¹å¸¸è§é—®é¢˜éƒ¨åˆ†ï¼‰

---

## ğŸ“ å¼•ç”¨

å¦‚æœä½¿ç”¨æœ¬ä»£ç ï¼Œè¯·å¼•ç”¨ç›¸å…³è®ºæ–‡ï¼ˆå¾…è¡¥å……ï¼‰ã€‚

---

**ç¥å®éªŒé¡ºåˆ©ï¼ğŸš€**

æœ€åæ›´æ–°: 2024
